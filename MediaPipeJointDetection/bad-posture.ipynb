{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Posture Detection with Voice Warning... Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaa\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "Exception ignored in: <function BSTR.__del__ at 0x000002383AE69E40>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishaa\\AppData\\Roaming\\Python\\Python311\\site-packages\\comtypes\\_post_coinit\\bstr.py\", line 26, in __del__\n",
      "    def __del__(self, _free: Callable[[\"BSTR\"], Any] = _SysFreeString) -> None:\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m     run_posture_detection()\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Posture Detection with Voice Warning... Press \u001b[39m\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to quit.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43mrun_posture_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mrun_posture_detection\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     45\u001b[39m image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m     46\u001b[39m image.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m results = \u001b[43mpose\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Convert back to BGR\u001b[39;00m\n\u001b[32m     50\u001b[39m image.flags.writeable = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[39m, in \u001b[36mPose.process\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np.ndarray) -> NamedTuple:\n\u001b[32m    165\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[32m    166\u001b[39m \n\u001b[32m    167\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m   results = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m results.pose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results.pose_landmarks.landmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[39m, in \u001b[36mSolutionBase.process\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m    334\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m._graph.add_packet_to_input_stream(\n\u001b[32m    336\u001b[39m         stream=stream_name,\n\u001b[32m    337\u001b[39m         packet=\u001b[38;5;28mself\u001b[39m._make_packet(input_stream_type,\n\u001b[32m    338\u001b[39m                                  data).at(\u001b[38;5;28mself\u001b[39m._simulated_timestamp))\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Posture detection + Voice Warning System (Mac/Windows/Linux)\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize TTS engine\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 170)  # speaking speed\n",
    "engine.setProperty('volume', 1.0)  # volume (0.0 to 1.0)\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speak a warning message.\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between three points (shoulder-hip-knee).\"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "def run_posture_detection():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert BGR â†’ RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Convert back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Key landmarks\n",
    "                shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "\n",
    "                # Calculate angle\n",
    "                angle = calculate_angle(shoulder, hip, knee)\n",
    "                \n",
    "                if angle > 160:\n",
    "                    posture = \"Good Posture\"\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    posture = \"Bad Posture\"\n",
    "                    color = (0, 0, 255)\n",
    "                    speak(\"Warning! Bad posture detected. Please sit straight.\")\n",
    "\n",
    "                # Display status\n",
    "                cv2.putText(image, posture, (50, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            cv2.imshow(\"Posture Detection\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting Posture Detection with Voice Warning... Press 'q' to quit.\")\n",
    "    run_posture_detection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
